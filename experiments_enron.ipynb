{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from segk import segk\n",
    "from utils import read_edgelist\n",
    "from evaluation import evaluate_classification, evaluate_clustering\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = dict()\n",
    "with open(\"datasets/enron/employees.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        tokens = line.split(\"\\t\")\n",
    "        tokens = re.split(r'\\s{2,}', tokens[1][:-1])\n",
    "        if len(tokens) >= 2:\n",
    "            name = tokens[0].split()[0].lower()+'.'+tokens[0].split()[1].lower()\n",
    "            class_labels[name] = tokens[1]\n",
    "\n",
    "name2id = dict()\n",
    "with open(\"datasets/enron/email-Enron-full-node-labels.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        tokens = line.split()\n",
    "        name = tokens[1].split('@')[0]\n",
    "        if name in class_labels:\n",
    "            name2id[name] = int(tokens[0])\n",
    "\n",
    "jobs = set(class_labels.values())\n",
    "jobs_count = dict()\n",
    "for name in class_labels:\n",
    "    if class_labels[name] in jobs_count:\n",
    "        jobs_count[class_labels[name]] += 1\n",
    "    else:\n",
    "        jobs_count[class_labels[name]] = 1\n",
    "\n",
    "reduced_labels = dict()\n",
    "for name in class_labels:\n",
    "    if name in name2id and class_labels[name] != 'N/A' and class_labels[name] != 'In House Lawyer':\n",
    "        if class_labels[name] == 'Managing Director':\n",
    "            reduced_labels[name2id[name]] = 'Director'\n",
    "        else:\n",
    "            reduced_labels[name2id[name]] = class_labels[name]\n",
    "\n",
    "\n",
    "nodes, edgelist = read_edgelist(\"datasets/enron/email-Enron-full-proj-graph.txt\", delimiter=' ', nodetype=int, cols=3)\n",
    "\n",
    "y = list()\n",
    "for node in nodes:\n",
    "    if node in reduced_labels:\n",
    "        y.append(reduced_labels[node])\n",
    "y = np.array(y)\n",
    "\n",
    "E_segk_sp = segk(nodes, edgelist, radius=2, dim=20, kernel='shortest_path')\n",
    "E_segk_wl = segk(nodes, edgelist, radius=2, dim=20, kernel='weisfeiler_lehman')\n",
    "\n",
    "algorithms = [\"SEGK-SP\", \"SEGK-WL\"]\n",
    "embeddings = [E_segk_sp, E_segk_wl]\n",
    "\n",
    "reduced_embeddings = list()\n",
    "for embedding_matrix in embeddings:\n",
    "    X = list()\n",
    "    for i,node in enumerate(nodes):\n",
    "        if node in reduced_labels:\n",
    "            X.append(embedding_matrix[i,:])\n",
    "    X = np.array(X)\n",
    "    reduced_embeddings.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEGK-SP\n",
      "Homogeneity: 0.23073888883315125\n",
      "Completeness: 0.08793008843427917\n",
      "Silhouette: 0.018343633073345317\n",
      "Accuracy: 0.27812222222222227\n",
      "F1-score: 0.1647360987953845\n",
      "\n",
      "SEGK-WL\n",
      "Homogeneity: 0.2888437396537913\n",
      "Completeness: 0.06353902966103214\n",
      "Silhouette: 0.3975811007287109\n",
      "Accuracy: 0.3499333333333334\n",
      "F1-score: 0.21774039531896677\n"
     ]
    }
   ],
   "source": [
    "homogeneity, completeness, silhouette = evaluate_clustering(reduced_embeddings, y)\n",
    "accs, f1 = evaluate_classification(reduced_embeddings, y)\n",
    "                      \n",
    "for i in range(len(algorithms)):\n",
    "    print(\"\\n\"+algorithms[i])\n",
    "    print(\"Homogeneity:\", homogeneity[i])\n",
    "    print(\"Completeness:\", completeness[i])\n",
    "    print(\"Silhouette:\", silhouette[i])\n",
    "    print(\"Accuracy:\", accs[i])\n",
    "    print(\"F1-score:\", f1[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
